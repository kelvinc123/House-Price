{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import re\n",
    "from importlib import reload\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from _lib.preprocess import preprocess_missing as prep\n",
    "from _lib.preprocess import get_instruction as info\n",
    "from _lib.preprocess_test import preprocess_missing as prep_test\n",
    "from _lib.create_output import output\n",
    "\n",
    "df = pd.read_csv(\"_database/Input/train.csv\", index_col = 0)\n",
    "\n",
    "df = prep(df)\n",
    "df = df.drop([1299, 935, 186, 347, 1231, 1183, 692, 955])\n",
    "X_data = df.drop(\"SalePrice\", axis = 1)\n",
    "y = df[\"SalePrice\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate polynomial features of numerical variables\n",
    "def gen_poly(data, degree):\n",
    "    '''\n",
    "    Input : Vector or matrix \n",
    "    \n",
    "    Return matrix of polynomial for each polynomial degree from 1 to degree calculated on each column\n",
    "    '''\n",
    "    \n",
    "    result = np.concatenate([np.power(data, d) for d in np.arange(1, degree + 1)], axis = 1)\n",
    "    return result\n",
    "\n",
    "df_type = pd.DataFrame({\"Columns\" : X_data.columns, \"Type\" : [str(X_data[col].dtype) for col in X_data.columns]})\n",
    "num_columns = df_type.loc[(df_type[\"Type\"] == \"int64\") | (df_type[\"Type\"] == \"float64\")][\"Columns\"]\n",
    "cat_columns = df_type.loc[(df_type[\"Type\"] == \"category\")][\"Columns\"]\n",
    "bool_columns = df_type.loc[df_type[\"Type\"] == \"bool\"][\"Columns\"]\n",
    "\n",
    "# Categories in categorical features\n",
    "list_categories = [np.array(info(col)) for col in cat_columns.values]\n",
    "list_categories[14] = np.arange(1, 11)\n",
    "list_categories[15] = np.arange(1, 11)\n",
    "\n",
    "\n",
    "# Polynomial degree\n",
    "poly_degree = 1\n",
    "\n",
    "get_numerical = FunctionTransformer(lambda x : x[num_columns.values].values, validate = False)\n",
    "\n",
    "get_category = FunctionTransformer(lambda x : x[cat_columns.values], validate = False)\n",
    "\n",
    "get_bool = FunctionTransformer(lambda x : x[bool_columns.values].values, validate = False)\n",
    "\n",
    "generate_poly = FunctionTransformer(lambda x : gen_poly(x, poly_degree), validate = False)\n",
    "\n",
    "pipeline_num_prep = Pipeline([('selector', get_numerical),\n",
    "                              ('poly', generate_poly)])\n",
    "\n",
    "pipeline_cat_prep = Pipeline([('selector', get_category),\n",
    "                              ('Dummy', OneHotEncoder(drop = 'first', sparse = False,\n",
    "                                                     categories = list_categories))])\n",
    "\n",
    "transformers = [ ('Numerical', pipeline_num_prep), ('Categorical', pipeline_cat_prep), ('Bool', get_bool) ]\n",
    "\n",
    "preprocess_union = FeatureUnion(transformer_list = transformers)\n",
    "\n",
    "pl = Pipeline([\n",
    "    ('union', preprocess_union)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pl.fit_transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ml.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msle = (np.sum((np.log(y_pred + 1) - np.log(y_test + 1))**2))/(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(msle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_log_error(y_test[y_pred > 0], y_pred[y_pred > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using poly degree > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_reg_pipeline(poly_degree):\n",
    "\n",
    "    get_numerical = FunctionTransformer(lambda x : x[num_columns.values].values, validate = False)\n",
    "\n",
    "    get_category = FunctionTransformer(lambda x : x[cat_columns.values], validate = False)\n",
    "\n",
    "    get_bool = FunctionTransformer(lambda x : x[bool_columns.values].values, validate = False)\n",
    "\n",
    "    generate_poly = FunctionTransformer(lambda x : gen_poly(x, poly_degree), validate = False)\n",
    "\n",
    "    pipeline_num_prep = Pipeline([('selector', get_numerical),\n",
    "                                  ('poly', generate_poly)])\n",
    "\n",
    "    pipeline_cat_prep = Pipeline([('selector', get_category),\n",
    "                                  ('Dummy', OneHotEncoder(drop = 'first', sparse = False,\n",
    "                                                         categories = list_categories))])\n",
    "\n",
    "    transformers = [ ('Numerical', pipeline_num_prep), ('Categorical', pipeline_cat_prep), ('Bool', get_bool) ]\n",
    "\n",
    "    preprocess_union = FeatureUnion(transformer_list = transformers)\n",
    "\n",
    "    pl = Pipeline([\n",
    "        ('union', preprocess_union)\n",
    "\n",
    "    ])\n",
    "    \n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "seed = 40\n",
    "msle_list = []\n",
    "for i in range(1, n):\n",
    "    pl = poly_reg_pipeline(i)\n",
    "    X = pl.fit_transform(X_data)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = seed)\n",
    "    ml = LinearRegression()\n",
    "    ml.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ml.predict(X_test)\n",
    "    msle = mean_squared_error(y_test, y_pred)\n",
    "    msle_list.append(msle)\n",
    "    \n",
    "    print(\"The MSLE for poly degree {} is : {}\".format(i, msle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to compare them using standard scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = poly_reg_pipeline(3)\n",
    "X = pl.fit_transform(X_data)\n",
    "y1 = df[\"SalePrice\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = np.logspace(-3, 1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.zeros(len(alpha_list))\n",
    "for i in np.arange(len(alpha_list)):\n",
    "    ml = Ridge(alpha = alpha_list[i])\n",
    "    ml.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ml.predict(X_test)\n",
    "    \n",
    "    mse[i] = mean_squared_error(y_test, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha_list, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list1 = np.logspace(-3, 2, 50)\n",
    "alpha_list2 = np.array([0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000])\n",
    "alpha_list = np.concatenate((alpha_list1, alpha_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha' : alpha_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GridSearchCV(ml, param_grid = params, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ml.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ml(x, y, ml, size = 1):\n",
    "    inds = np.arange(x.shape[0])\n",
    "    bs_rep = np.empty(size)\n",
    "    \n",
    "    for i in range(size):\n",
    "        \n",
    "        bs_inds = np.random.choice(inds, size = len(inds))\n",
    "        x_bs = x[bs_inds]\n",
    "        y_bs = y.values.reshape(-1,1)[bs_inds]\n",
    "        ml.fit(x_bs, y_bs)\n",
    "        \n",
    "        y_bs_pred = ml.predict(X_test)\n",
    "        \n",
    "        bs_rep[i] = mean_squared_error(y_test, y_bs_pred)\n",
    "        \n",
    "    return bs_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bss = bootstrap_ml(X_train, y_train, ml, size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bss[bss < 0.02], bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## another polynomial degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = poly_reg_pipeline(5)\n",
    "X = pl.fit_transform(X_data)\n",
    "y1 = df[\"SalePrice\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GridSearchCV(ml, param_grid = params, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_param = cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ml.predict(X_test)\n",
    "y_pred_train = ml.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GridSearchCV(ml, param_grid = params, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_param = cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ml.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'min_samples_leaf' : np.linspace(0.1, 1, 50),\n",
    "         'max_depth' : np.linspace(1, 300, 100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GridSearchCV(ml, param_grid = params, cv = 10, n_jobs=-1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ml.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'min_samples_leaf' : np.linspace(0.0001, 0.001, 10),\n",
    "         'max_depth' : np.linspace(130, 140, 5),\n",
    "         'n_estimators' : np.arange(33, 39)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GridSearchCV(ml, param_grid = params, n_jobs=-1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ml.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha' : np.linspace(0.5, 0.7, 5),\n",
    "          'max_depth' : np.arange(1, 4),\n",
    "         'max_features' : np.linspace(0.2, 0.6, 10),\n",
    "         'n_estimators' : np.linspace(60, 80, 10),\n",
    "         'subsample' : np.linspace(0.4, 0.6, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GridSearchCV(ml, param_grid = params, n_jobs=-1, verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15000 candidates, totalling 75000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 492 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2508 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 5100 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 8268 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 12012 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 16332 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done 21228 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=-1)]: Done 26700 tasks      | elapsed:   38.0s\n",
      "[Parallel(n_jobs=-1)]: Done 32748 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 39372 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=-1)]: Done 46572 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 54348 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 62700 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 71628 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 75000 out of 75000 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-ea31fe3eeaeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1480\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m             \u001b[1;31m# init state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1482\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1484\u001b[0m             \u001b[1;31m# fit initial model and initialize raw predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_init_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m         self.estimators_ = np.empty((self.n_estimators, self.loss_.K),\n\u001b[1;32m-> 1352\u001b[1;33m                                     dtype=np.object)\n\u001b[0m\u001b[0;32m   1353\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_score_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m         \u001b[1;31m# do oob?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = GradientBoostingRegressor(alpha = 0.5, max_depth = 1, max_features = 0.2, n_estimators=60, subsample = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ml.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ad1b8db7c95a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcombined_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregressors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregressors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Working on regressor {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "combined_pred = np.zeros(len(y_test))\n",
    "mses = np.zeros(len(regressors) +1)\n",
    "\n",
    "for i in np.arange(len(regressors)):\n",
    "    print(\"Working on regressor {}\".format(i+1))\n",
    "    reg = regressors[i]\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = reg.predict(X_test)\n",
    "    mses[i] = mean_squared_error(y_test, y_pred)\n",
    "    combined_pred = combined_pred + y_pred\n",
    "\n",
    "combined_pred = combined_pred / len(regressors)\n",
    "mses[len(regressors)] = mean_squared_error(y_test, combined_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [LinearRegression(), Ridge(), Lasso(),\n",
    "              RandomForestRegressor(),\n",
    "              GradientBoostingRegressor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_linreg = {'normalize' : [True, False]}\n",
    "params_ridgelasso = {'alpha' : alpha_list}\n",
    "params_rf = {'min_samples_leaf' : np.linspace(0.0001, 0.001, 10),\n",
    "         'max_depth' : np.linspace(130, 140, 5),\n",
    "         'n_estimators' : np.arange(33, 39)}\n",
    "params_sgbr = {'alpha' : np.linspace(0.5, 0.7, 5),\n",
    "          'max_depth' : np.arange(1, 4),\n",
    "         'max_features' : np.linspace(0.2, 0.6, 10),\n",
    "         'n_estimators' : np.linspace(60, 80, 10),\n",
    "         'subsample' : np.linspace(0.4, 0.6, 10)}\n",
    "params_list = [params_linreg, params_ridgelasso, params_ridgelasso, params_rf, params_sgbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  20 | elapsed:    1.5s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:    1.5s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  20 | elapsed:    1.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : {'normalize': False}\n",
      "Working on Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 617 out of 640 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 640 out of 640 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : {'alpha': 7.543120063354623}\n",
      "Working on Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False)\n",
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 617 out of 640 | elapsed:   15.4s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 640 out of 640 | elapsed:   15.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : {'alpha': 0.001}\n",
      "Working on RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False)\n",
      "Fitting 10 folds for each of 300 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1544 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2024 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2568 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : {'max_depth': 130.0, 'min_samples_leaf': 0.0005, 'n_estimators': 34}\n"
     ]
    }
   ],
   "source": [
    "combined_pred = np.zeros(X_test.shape[0])\n",
    "\n",
    "for i in np.arange(len(regressors)-1):\n",
    "    reg = regressors[i]\n",
    "    print(\"Working on {}\".format(reg))\n",
    "    params = params_list[i]\n",
    "    \n",
    "    cv = GridSearchCV(reg, param_grid = params, cv = 10, n_jobs=-1, verbose = 3)\n",
    "    cv.fit(X, y)\n",
    "    print(\"The best parameters are : {}\".format(cv.best_params_))\n",
    "    \n",
    "    ml = cv.best_estimator_\n",
    "    y_pred = ml.predict(X_test)\n",
    "    combined_pred = combined_pred + y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgbr_best = cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = GradientBoostingRegressor(alpha = 0.5, max_depth = 1, max_features = 0.2, n_estimators = 60, subsample = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.fit(X, y)\n",
    "y_pred = ml.predict(X_test)\n",
    "combined_pred = combined_pred + y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pred = np.exp(combined_pred / len(regressors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"_database/Input/test.csv\", index_col = 0)\n",
    "test_index = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = prep_test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pl.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [LinearRegression(), Ridge(), Lasso(),\n",
    "              RandomForestRegressor(),\n",
    "              GradientBoostingRegressor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_linreg = {'normalize' : [True, False]}\n",
    "params_ridgelasso = {'alpha' : alpha_list}\n",
    "params_rf = {'min_samples_leaf' : np.linspace(0.0001, 0.001, 10),\n",
    "         'max_depth' : np.linspace(130, 140, 5),\n",
    "         'n_estimators' : np.arange(33, 39)}\n",
    "params_sgbr = {'alpha' : np.linspace(0.5, 0.7, 5),\n",
    "          'max_depth' : np.arange(1, 4),\n",
    "         'max_features' : np.linspace(0.2, 0.6, 10),\n",
    "         'n_estimators' : np.linspace(60, 80, 10),\n",
    "         'subsample' : np.linspace(0.4, 0.6, 10)}\n",
    "params_list = [params_linreg, params_ridgelasso, params_ridgelasso, params_rf, params_sgbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on regressor 1\n",
      "Working on regressor 2\n",
      "Working on regressor 3\n",
      "Working on regressor 4\n",
      "Working on regressor 5\n"
     ]
    }
   ],
   "source": [
    "combined_pred = np.zeros(X_test.shape[0])\n",
    "\n",
    "for i in np.arange(len(regressors)-1):\n",
    "    reg = regressors[i]\n",
    "    print(\"Working on {}\".format(reg))\n",
    "    params = params_list[i]\n",
    "    \n",
    "    cv = GridSearchCV(reg, param_grid = params, cv = 10, n_jobs=-1, verbose = 3)\n",
    "    cv.fit(X, y)\n",
    "    print(\"The best parameters are : {}\".format(cv.best_params_))\n",
    "    \n",
    "    ml = cv.best_estimator_\n",
    "    y_pred = ml.predict(X_test)\n",
    "    combined_pred = combined_pred + y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = GradientBoostingRegressor(alpha = 0.5, max_depth = 1, max_features = 0.2, n_estimators = 60, subsample = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.fit(X, y)\n",
    "y_pred = ml.predict(X_test)\n",
    "combined_pred = combined_pred + y_pred\n",
    "combined_pred = np.exp(combined_pred / len(regressors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame({\"id\" : test_index,\n",
    "             \"SalePrice\" : combined_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv(\"_database/Output/Combined.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
